{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8764fea5",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b58674d",
   "metadata": {},
   "source": [
    "**Consolidate**\n",
    "* Organize imaging/behavior videos recorded in a single day for one animal into a single folder. The imaging field of view must be consistent for all data folders being processed (ie miniscope was not removed from the animal between recording sessions).\n",
    "\n",
    "**Concatenate**\n",
    "* Concatenate (ie merge together) all behavior videos and corresponding timestamp files. Many post-processing position analysis pipelines, like DeepLabCut, do not have a function that does this. \n",
    "* Imaging videos will *not* be be concatenated because many calcium extraction pipelines include this step (ie MiniAn). However, corresponding imaging timestamp and head orientaion files will be concatenated. \n",
    "\n",
    "**Downsample**\n",
    "* Downsample the merged *behavior* video and its corresponding timestamp file by a user-defined `downsample_factor`. Both the original and downsampled files will be saved. \n",
    ">**Why downsample behavior video?** In later steps not included in this notebook, the user may decide to downsample the *imaging* videos to make downstream calcium extraction more efficient. Before moving forward with position analysis of behavior videos, the user should decide whether to use the original or downsampled videos. This will all depend on how calcium signals are extracted. Aligning behavior-imaging data will be significantly simpler if both imaging AND behavior videos are post-processed using the same sampling rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49821c28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Folder structure</strong>\n",
    "\n",
    "This notebook assumes that the data in `parent_folders` are stored in hierarchically arranged folders created from UCLA Miniscope software, as shown below:\n",
    "\n",
    "```\n",
    "M1\n",
    "│habituation  \n",
    "│\n",
    "└───trial1\n",
    "│   │\n",
    "│   └───behaviorTracker\n",
    "│   └───experiment\n",
    "│   └───Minicam\n",
    "│       │   0.avi\n",
    "│       │   1.avi\n",
    "│       │   ...\n",
    "│       │   timeStamps.csv      \n",
    "│   └───My_V4_Miniscope \n",
    "│       │   0.avi\n",
    "│       │   1.avi\n",
    "│       │   ...\n",
    "│       │   timeStamps.csv \n",
    "│       │   headOrientation.csv \n",
    "│   \n",
    "└───trial2\n",
    "│   │\n",
    "│   └───behaviorTracker\n",
    "│   └───experiment\n",
    "│   └───Minicam\n",
    "│       │   0.avi\n",
    "│       │   1.avi\n",
    "│       │   2.avi\n",
    "│       │   timeStamps.csv    \n",
    "│   └───My_V4_Miniscope \n",
    "│       │   0.avi\n",
    "│       │   1.avi\n",
    "│       │   2.avi\n",
    "│       │   timeStamps.csv \n",
    "│       │   headOrientation.csv\n",
    "```\n",
    "\n",
    "Using the example above: Animal M1 is habituated to an arena across two trials (`animalID = M1` and `experimentID = habituation`) *without removing the miniscope between trials.* Given this, it is assumed the miniscope imaging field of view is consistent across trials. If calcium extraction analysis (ie MiniAn, CNMF-E) were performed on each trial independently, additional analysis would be required to match cells between trials. This is time consuming and tricky. Instead, this notebook will organize and concatenate the trials into the following **`output_folder` structure** so they can be analyzed as single session:\n",
    "    \n",
    "```\n",
    "Processed\n",
    "│\n",
    "└─M1_habituation  \n",
    "  │\n",
    "  └──Behavior\n",
    "     │   M1_habituation_mergedVideo.avi\n",
    "     │   M1_habituation_mergedVideoDownsampled.avi\n",
    "     │   M1_habituation_timeStamps.csv \n",
    "     │   M1_habituation_timeStampsDownsampled.csv \n",
    "     │   0.avi\n",
    "     │   1.avi\n",
    "     │   2.avi\n",
    "     │   3.avi\n",
    "     │   4.avi\n",
    "     │   5.avi\n",
    "  │    \n",
    "  └──Imaging\n",
    "     │   M1_habituation_timeStamps.csv \n",
    "     │   M1_habituation_timeStampsDownsampled.csv \n",
    "     │   M1_habituation_headOrientation.csv \n",
    "     │   M1_habituation_headOrientationDownsampled.csv \n",
    "     │   0.avi\n",
    "     │   1.avi\n",
    "     │   2.avi\n",
    "     │   3.avi \n",
    "     │   4.avi\n",
    "     │   5.avi\n",
    "│\n",
    "└─BehaviorVideos_positionAnalysis\n",
    "  │   M1_habituation_mergedVideo.avi\n",
    "  │   M2_habituation_mergedVideo.avi\n",
    "│\n",
    "└─BehaviorVideos_positionAnalysis_Downsampled\n",
    "  │   M1_habituation_mergedVideoDownsampled.avi\n",
    "  │   M2_habituation_mergedVideoDownsampled.avi\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21f4d9",
   "metadata": {},
   "source": [
    "## Initialize: import necessary dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc94e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592232d",
   "metadata": {},
   "source": [
    "## Filename structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e7dba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Provide animal and experiment info to create unique filenames:</strong>\n",
    "\n",
    "`animalID` and `experimentID` will be used to create a `fileID` to rename and save files in `output_folder`. This is an opportunity to ensure filenames are both specific enough to distinguish animals in a cohort, but general enough to easily group experiments or conditions. *Try to consider downstream analyses and how animals and/or experiments will be grouped when developing naming conventions.*\n",
    "\n",
    "* `animalID:` Include 'M' (male) or 'F'(female) along with number of animal.\n",
    "* `experimentID:` Be concise and consistent with experiment descriptions. Try not to use spaces or special characters. Dates are not recommended.\n",
    "\n",
    "**Good examples**\n",
    "* `animalID = M1`,`animalID = M1`, `animalID = M1`\n",
    "* `experimentID = baseline`, `experimentID = 5sdelay`, `experimentID = 5sec`\n",
    "\n",
    "**Not as good examples**\n",
    "* `animalID = 1`, `animalID = M1_ctrl`, `animalID = M1_stress`\n",
    "* `experimentID = 100323_baseline`, `experimentID = 5_s_delay`, `experimentID = delay_5s`\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67970870",
   "metadata": {},
   "source": [
    "## Set path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b85c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Specify directories to pull and put data:</strong>\n",
    "\n",
    "* `parent_folders:` Folder for each recording session containing \"Minicam\" & \"My_V4_Miniscope\" subfolders\n",
    "* `output_folder:` `fileID` will be used to create folders in this user-defined directory where data will be saved \n",
    "* `behavior_video_folder= BehaviorVideos_positionAnalysis`: A subfolder created within `output_folder` directory where all merged behavior videos from **all animals in a cohort** are saved. This can be useful for pipelines such as DeepLabCut (DLC) that require that all videos are in a single folder.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c928b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animal and experiment information\n",
    "animalID='F5937'\n",
    "experimentID='ss2'\n",
    "\n",
    "#List of parent folder directories (in the order you want)\n",
    "parent_folders = [\n",
    "    \"H:/COHORT4/F5937/ss2_062422_1\",\n",
    "    \"H:/COHORT4/F5937/ss2_062422_2\",\n",
    "    # Add more folders as needed\n",
    "]\n",
    "\n",
    "#Directory where compiled behavior and imaging files will be saved\n",
    "output_folder = \"H:/COHORT4/Processed\" \n",
    "\n",
    "#Downsampling factor\n",
    "downsample_factor = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6665e30",
   "metadata": {},
   "source": [
    "# Behavior video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9086c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video concatenation complete. The concatenated video is saved as 'mergedVideo.avi'.\n",
      "Video downsampling complete. The downsampled video is saved as '_mergedVideoDownsampled.avi'.\n"
     ]
    }
   ],
   "source": [
    "#Prefix for \"_mergedVideo.avi\" file\n",
    "fileID= animalID + '_' + experimentID\n",
    "\n",
    "#Directory with copy of all merged behavior videos and timestamp files\n",
    "behavior_video_folder = output_folder + '/Behavior_positionAnalysis'\n",
    "#Directory with copy of all imaging timestamp files videos\n",
    "imaging_video_folder = output_folder + '/Imaging_calciumAnalysis'\n",
    "\n",
    "output_folder = output_folder + '/' + fileID\n",
    "\n",
    "# Function to get a list of all CSV files containing \"_timeStamps.csv\"\n",
    "def get_timestamp_csv_files(folder):\n",
    "    timestamp_csv_files = [f for f in os.listdir(folder) if f.endswith('.csv') and \"_timeStamps.csv\" in f]\n",
    "    return timestamp_csv_files\n",
    "\n",
    "# Function to get a list of all AVI files and sort them by name\n",
    "def get_sorted_avi_files(folder):\n",
    "    avi_files = [f for f in os.listdir(folder) if f.endswith('.avi')]\n",
    "    avi_files.sort()\n",
    "    return avi_files\n",
    "\n",
    "def update_concatenated_timeStamps(compiled_folder, csv_file, fileID):\n",
    "    file_path = os.path.join(compiled_folder, csv_file)\n",
    "\n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    concatenated_data = pd.DataFrame()\n",
    "\n",
    "    # Initialize a variable to keep track of the total frame count\n",
    "    total_frames = 0\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename \"Frame\" to \"Frame Rate\" and \"Time\" to \"Time Stamp (ms)\"\n",
    "        df = df.rename(columns={'Frame Number': 'Frame', 'Time Stamp (ms)': 'Time'})\n",
    "        \n",
    "         # Remove the 3rd column\n",
    "        df = df.drop(columns=['Buffer Index'])\n",
    "        \n",
    "        # Add a 'Frame' column that counts from 1 to the end of the column\n",
    "        df['Frame Number'] = range(1, len(df) + 1)\n",
    "\n",
    "        # Calculate the sampling frequency from the 'Time Stamp (ms)' column\n",
    "        sampling_frequency = 1000 / (df['Time'].iloc[1] - df['Time'].iloc[0])\n",
    "\n",
    "        # Add a 'Time (ms)' column that counts up from 0 using the sampling frequency interval\n",
    "        df['Time Stamp(ms)'] = [i / sampling_frequency for i in range(len(df))]\n",
    "        \n",
    "         # Remove the 1st column\n",
    "        df = df.drop(columns=['Frame'])\n",
    "        \n",
    "        # Remove the 2nd column\n",
    "        df = df.drop(columns=['Time'])\n",
    "\n",
    "        # Append the data to the concatenated_data DataFrame\n",
    "        concatenated_data = concatenated_data.append(df, ignore_index=True)\n",
    "\n",
    "        # Update the total frame count\n",
    "        total_frames += len(df)\n",
    "        \n",
    "       \n",
    "    else:\n",
    "        print(f\"File '{csv_file}' not found in folder '{compiled_folder}'\")\n",
    "\n",
    "    # Extract the base name (without extension)\n",
    "    base_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "    # Get the last part of the base name\n",
    "    last_part = base_name.split(\"_\")[-1]\n",
    "\n",
    "    # Save the concatenated data to a new CSV file\n",
    "    name = fileID + '_' + last_part + '.csv'\n",
    "    concatenated_data.to_csv(os.path.join(compiled_folder, name), index=False)\n",
    "\n",
    "# Function to process Minicam folders\n",
    "def process_minicam_folders(parent_folders, output_folder):\n",
    "    compiled_folder = os.path.join(output_folder, \"Behavior\")\n",
    "    os.makedirs(compiled_folder, exist_ok=True)\n",
    "    \n",
    "    concatenated_timestamps = pd.DataFrame()  # Initialize an empty DataFrame to store concatenated timestamps\n",
    "    \n",
    "    for index, parent_folder in enumerate(parent_folders):\n",
    "        avi_files = get_sorted_avi_files(os.path.join(parent_folder, \"Minicam\"))\n",
    "        #timestamps_file = os.path.join(parent_folder, \"Minicam\", \"timeStamps.csv\")\n",
    "        timestamp_csv_files = get_timestamp_csv_files(os.path.join(parent_folder, \"Minicam\"))\n",
    "\n",
    "\n",
    "        # Copy AVI files to Behavior compiled folder and rename\n",
    "        for i, avi_file in enumerate(avi_files):\n",
    "            new_name = f\"{index * len(avi_files) + i}.avi\"  # Corrected naming here\n",
    "            shutil.copy(os.path.join(parent_folder, \"Minicam\", avi_file), os.path.join(compiled_folder, new_name))\n",
    "            \n",
    "        # Copy timestamps file and rename\n",
    "        for timestamp_file in timestamp_csv_files:\n",
    "            new_timestamps_name = f\"{index}_{timestamp_file}\"\n",
    "            shutil.copy(os.path.join(parent_folder, \"Minicam\", timestamp_file), os.path.join(compiled_folder, new_timestamps_name))\n",
    "            timestamps_data = pd.read_csv(os.path.join(compiled_folder, new_timestamps_name))\n",
    "            # Concatenate to the main DataFrame\n",
    "            concatenated_timestamps = pd.concat([concatenated_timestamps, timestamps_data])\n",
    "            os.remove(os.path.join(compiled_folder, new_timestamps_name))\n",
    "            \n",
    "    # Save the concatenated timestamps to a new file\n",
    "    nameA = \"timeStamps.csv\"\n",
    "    concatenated_timestamps.to_csv(os.path.join(compiled_folder, nameA), index=False)\n",
    "\n",
    "    # Create a downsampled version of the timestamps DataFrame (downsampled by 2)\n",
    "    downsampled_timestamps = concatenated_timestamps.iloc[::2].reset_index(drop=True)\n",
    "    nameB = \"timeStampsDownsampled.csv\"\n",
    "    downsampled_timestamps.to_csv(os.path.join(compiled_folder, nameB), index=False)\n",
    "\n",
    "    update_concatenated_timeStamps(compiled_folder, nameA, fileID)\n",
    "    update_concatenated_timeStamps(compiled_folder, nameB, fileID)\n",
    "\n",
    "    os.remove(os.path.join(compiled_folder, nameA))\n",
    "    os.remove(os.path.join(compiled_folder, nameB))\n",
    "    \n",
    "            \n",
    "    # Check and adjust frame rate to 30 FPS (assuming all AVIs have the same frame rate)\n",
    "    for avi_file in avi_files:\n",
    "        video_path = os.path.join(compiled_folder, f\"{index * len(avi_files) + i}.avi\")  # Corrected naming here\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if frame_rate != 30:\n",
    "            print(f\"Changing frame rate for {video_path} to 30 FPS\")\n",
    "            out = cv2.VideoWriter(\n",
    "                video_path.replace(\".avi\", \"_30fps.avi\"),\n",
    "                cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                30,\n",
    "                (int(cap.get(3)), int(cap.get(4)))\n",
    "            )\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                out.write(frame)\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            os.remove(video_path)\n",
    "            os.rename(video_path.replace(\".avi\", \"_30fps.avi\"), video_path)\n",
    "\n",
    "\n",
    "# Function to concatenate AVI videos\n",
    "def concatenate_avi_videos(input_folder, output_file):\n",
    "    video_files = [f for f in os.listdir(input_folder) if f.endswith('.avi')]\n",
    "    video_files.sort()\n",
    "\n",
    "    frames = []\n",
    "    \n",
    "    for file in video_files:\n",
    "        video = cv2.VideoCapture(os.path.join(input_folder, file))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        video.release()\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    output = cv2.VideoWriter(output_file, fourcc, 30, (frames[0].shape[1], frames[0].shape[0]))\n",
    "\n",
    "    for frame in frames:\n",
    "        output.write(frame)\n",
    "\n",
    "    output.release()\n",
    "    \n",
    "# Function to downsample an AVI video by 2 and reduce the video length\n",
    "def downsample_avi_video(input_file, output_file, downsample_factor):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = int(cap.get(5))\n",
    "    \n",
    "    new_frame_width = frame_width \n",
    "    new_frame_height = frame_height\n",
    "    new_frame_rate = frame_rate# * downsample_factor\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, new_frame_rate, (new_frame_width, new_frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Downsample the frame by 2\n",
    "        if frame_count % downsample_factor == 0:\n",
    "            frame = cv2.resize(frame, (new_frame_width, new_frame_height))\n",
    "            out.write(frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Ensure the output_folder exists, or create it if it doesn't\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process Minicam folders\n",
    "process_minicam_folders(parent_folders, output_folder)\n",
    "\n",
    "# Concatenate AVI videos from the Imaging compiled folder\n",
    "name=fileID + '_mergedVideo.avi'\n",
    "concatenated_video_output = os.path.join(output_folder,\"Behavior\", name)\n",
    "concatenate_avi_videos(os.path.join(output_folder, \"Behavior\"), concatenated_video_output)\n",
    "\n",
    "nameDownsampled=fileID + '_mergedVideoDownsampled.avi'\n",
    "output_video_path = os.path.join(output_folder, \"Behavior\", nameDownsampled)\n",
    "downsample_avi_video(concatenated_video_output, output_video_path, downsample_factor)\n",
    "\n",
    "# Move merged videos to shared folder for postion analysis (ie DeepLabCut)\n",
    "\n",
    "# Use the user-defined folder to create a downsampled folder\n",
    "downsampled_behavior_video_folder = behavior_video_folder + '_Downsampled'\n",
    "\n",
    "# Ensure the behavior_video_folder exists, or create it if it doesn't\n",
    "os.makedirs(behavior_video_folder, exist_ok=True)\n",
    "\n",
    "# Ensure the downsampled_behavior_video_folder exists, or create it if it doesn't\n",
    "os.makedirs(downsampled_behavior_video_folder, exist_ok=True)\n",
    "\n",
    "# Copy the concatenated video to the behavior_video_folder\n",
    "shutil.copy(concatenated_video_output, behavior_video_folder)\n",
    "\n",
    "# Copy the concatenated video to the behavior_video_folder\n",
    "shutil.copy(concatenated_video_output, downsampled_behavior_video_folder)\n",
    "\n",
    "\n",
    "print(\"Video concatenation complete. The concatenated video is saved as 'mergedVideo.avi'.\")\n",
    "print(\"Video downsampling complete. The downsampled video is saved as '_mergedVideoDownsampled.avi'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d910392",
   "metadata": {},
   "source": [
    "# Imaging video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d111c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 2/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 3/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 4/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 5/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 6/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 7/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 8/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 9/9 in folder H:/COHORT4/F5937/ss2_062422_1\n",
      "Processing file 1/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 2/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 3/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 4/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 5/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 6/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 7/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 8/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 9/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 10/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 11/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 12/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 13/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 14/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 15/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 16/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 17/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 18/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 19/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 20/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 21/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 22/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 23/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 24/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 25/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 26/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Processing file 27/27 in folder H:/COHORT4/F5937/ss2_062422_2\n",
      "Total frames timestamp file: 34566\n",
      "Total frames timestamp file: 17283\n",
      "Total frames head orientation file: 34566\n",
      "Total frames head orientation file: 17283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'H:/COHORT4/Processed/Imaging_calciumAnalysis_Downsampled\\\\F5937_ss2_timeStampsDownsampled.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine videos from trials in a single day's session, including time stamp files\n",
    "\n",
    "# Put My_V4_Miniscope videos into Imaging compiled folder\n",
    "\n",
    "# Function to get a list of all CSV files containing \"_timeStamps.csv\"\n",
    "def get_timestamp_csv_files(folder):\n",
    "    timestamp_csv_files = [f for f in os.listdir(folder) if f.endswith('.csv') and \"_timeStamps.csv\" in f]\n",
    "    return timestamp_csv_files\n",
    "\n",
    "def get_head_orientation_csv_files(folder):\n",
    "    head_orientation_csv_files = [f for f in os.listdir(folder) if f.endswith('.csv') and \"_headOrientation.csv\" in f]\n",
    "    return head_orientation_csv_files\n",
    "\n",
    "# Function to get a list of all AVI files and sort them by name\n",
    "def get_sorted_avi_files(folder):\n",
    "    avi_files = [f for f in os.listdir(folder) if f.endswith('.avi')]\n",
    "    avi_files.sort()\n",
    "    return avi_files\n",
    "\n",
    "def update_concatenated_timeStamps(compiled_folder, csv_file, fileID):\n",
    "    file_path = os.path.join(compiled_folder, csv_file)\n",
    "\n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    concatenated_data = pd.DataFrame()\n",
    "\n",
    "    # Initialize a variable to keep track of the total frame count\n",
    "    total_frames = 0\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename \"Frame Rate\" to \"Frame\"; and \"Time Stamp (ms)\" to \"Time\"\n",
    "        df = df.rename(columns={'Frame Number': 'Frame', 'Time Stamp (ms)': 'Time'})\n",
    "        \n",
    "         # Remove the 3rd column\n",
    "        df = df.drop(columns=['Buffer Index'])\n",
    "        \n",
    "        # Add a 'Frame' column that counts from 1 to the end of the column\n",
    "        df['Frame Number'] = range(1, len(df) + 1)\n",
    "\n",
    "        # Calculate the sampling frequency from the 'Time Stamp (ms)' column\n",
    "        sampling_frequency = 1000 / (df['Time'].iloc[1] - df['Time'].iloc[0])\n",
    "\n",
    "        # Add a 'Time (ms)' column that counts up from 0 using the sampling frequency interval\n",
    "        df['Time Stamp(ms)'] = [i / sampling_frequency for i in range(len(df))]\n",
    "        \n",
    "         # Remove the 1st column\n",
    "        df = df.drop(columns=['Frame'])\n",
    "        \n",
    "        # Remove the 2nd column\n",
    "        df = df.drop(columns=['Time'])\n",
    "\n",
    "        # Append the data to the concatenated_data DataFrame\n",
    "        concatenated_data = concatenated_data.append(df, ignore_index=True)\n",
    "\n",
    "        # Update the total frame count\n",
    "        total_frames += len(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"File '{csv_file}' not found in folder '{compiled_folder}'\")\n",
    "\n",
    "    # Extract the base name (without extension)\n",
    "    base_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "    # Get the last part of the base name\n",
    "    last_part = base_name.split(\"_\")[-1]\n",
    "\n",
    "    # Save the concatenated data to a new CSV file\n",
    "    name = fileID + '_' + last_part + '.csv'\n",
    "    concatenated_data.to_csv(os.path.join(compiled_folder, name), index=False)\n",
    "\n",
    "\n",
    "    # Print the total frame count\n",
    "    print(f\"Total frames timestamp file: {total_frames}\")\n",
    "\n",
    "def update_concatenated_headorientation(compiled_folder, csv_file, fileID):\n",
    "    file_path = os.path.join(compiled_folder, csv_file)\n",
    "\n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    concatenated_data = pd.DataFrame()\n",
    "\n",
    "    # Initialize a variable to keep track of the total frame count\n",
    "    total_frames = 0\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Rename \"Time Stamp (ms)\" to \"Time\"\n",
    "        df = df.rename(columns={'Time Stamp (ms)': 'Time'})\n",
    "        \n",
    "        # Add a 'Frame' column that counts from 1 to the end of the column\n",
    "        df['Frame Number'] = range(1, len(df) + 1)\n",
    "\n",
    "        # Calculate the sampling frequency from the 'Time Stamp (ms)' column\n",
    "        sampling_frequency = 1000 / (df['Time'].iloc[1] - df['Time'].iloc[0])\n",
    "\n",
    "        # Add a 'Time (ms)' column that counts up from 0 using the sampling frequency interval\n",
    "        df['Time Stamp(ms)'] = [i / sampling_frequency for i in range(len(df))]\n",
    "        \n",
    "        # Remove the 2nd column\n",
    "        df = df.drop(columns=['Time'])\n",
    "\n",
    "        # Append the data to the concatenated_data DataFrame\n",
    "        concatenated_data = concatenated_data.append(df, ignore_index=True)\n",
    "\n",
    "        # Update the total frame count\n",
    "        total_frames += len(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"File '{csv_file}' not found in folder '{compiled_folder}'\")\n",
    "\n",
    "    # Extract the base name (without extension)\n",
    "    base_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "    # Get the last part of the base name\n",
    "    last_part = base_name.split(\"_\")[-1]\n",
    "\n",
    "    # Save the concatenated data to a new CSV file\n",
    "    name = fileID + '_' + last_part + '.csv'\n",
    "    concatenated_data.to_csv(os.path.join(compiled_folder, name), index=False)\n",
    "\n",
    "\n",
    "    # Print the total frame count\n",
    "    print(f\"Total frames head orientation file: {total_frames}\")\n",
    "\n",
    "def process_imaging_folders(parent_folders, output_folder):\n",
    "    compiled_folder = os.path.join(output_folder, \"Imaging\")\n",
    "    os.makedirs(compiled_folder, exist_ok=True)\n",
    "\n",
    "    concatenated_timestamps = pd.DataFrame()  # Initialize an empty DataFrame to store concatenated timestamps\n",
    "    concatenated_headorientation = pd.DataFrame()  # Initialize an empty DataFrame to store concatenated timestamps\n",
    "\n",
    "    for index, parent_folder in enumerate(parent_folders):\n",
    "        avi_files = get_sorted_avi_files(os.path.join(parent_folder, \"My_V4_Miniscope\"))\n",
    "        timestamp_csv_files = get_timestamp_csv_files(os.path.join(parent_folder, \"My_V4_Miniscope\"))\n",
    "\n",
    "        #head_orientation_file = os.path.join(parent_folder, \"My_V4_Miniscope\", \"headOrientation.csv\")\n",
    "        head_orientation_csv_files = get_head_orientation_csv_files(os.path.join(parent_folder, \"My_V4_Miniscope\"))\n",
    "\n",
    "\n",
    "        # Copy AVI files to Imaging compiled folder and rename\n",
    "        for i, avi_file in enumerate(avi_files):\n",
    "            new_name = f\"{index * len(avi_files) + i}.avi\"  # Corrected naming here\n",
    "            shutil.copy(os.path.join(parent_folder, \"My_V4_Miniscope\", avi_file), os.path.join(compiled_folder, new_name))\n",
    "            print(f\"Processing file {i + 1}/{len(avi_files)} in folder {parent_folder}\")\n",
    "            \n",
    "        # Copy timestamps file and rename\n",
    "        for timestamps_file in timestamp_csv_files:\n",
    "            new_timestamps_name = f\"{index}_{timestamps_file}\"\n",
    "            shutil.copy(os.path.join(parent_folder, \"My_V4_Miniscope\", timestamps_file), os.path.join(compiled_folder, new_timestamps_name))   \n",
    "            timestamps_data = pd.read_csv(os.path.join(compiled_folder, new_timestamps_name))\n",
    "            # Concatenate to the main DataFrame\n",
    "            concatenated_timestamps = pd.concat([concatenated_timestamps, timestamps_data])\n",
    "            os.remove(os.path.join(compiled_folder, new_timestamps_name))\n",
    "            \n",
    "    \n",
    "        # Copy head orientation file and rename\n",
    "        for head_orientation_file in head_orientation_csv_files:\n",
    "            new_head_orientation_name = f\"{index}_headOrientation.csv\"\n",
    "            shutil.copy(os.path.join(parent_folder, \"My_V4_Miniscope\", head_orientation_file), os.path.join(compiled_folder, new_head_orientation_name))\n",
    "            headorientation_data = pd.read_csv(os.path.join(compiled_folder, new_head_orientation_name))\n",
    "            # Concatenate to the main DataFrame\n",
    "            concatenated_headorientation = pd.concat([concatenated_headorientation, headorientation_data])\n",
    "            os.remove(os.path.join(compiled_folder, new_head_orientation_name))\n",
    "\n",
    "    # Save the concatenated timestamps to a new file\n",
    "    nameA = fileID + \"_timeStamps.csv\"\n",
    "    concatenated_timestamps.to_csv(os.path.join(compiled_folder, nameA), index=False)\n",
    "\n",
    "    # Create a downsampled version of the timestamps DataFrame (downsampled by 2)\n",
    "    downsampled_timestamps = concatenated_timestamps.iloc[::2].reset_index(drop=True)\n",
    "    nameB = fileID + \"_timeStampsDownsampled.csv\"\n",
    "    downsampled_timestamps.to_csv(os.path.join(compiled_folder, nameB), index=False)\n",
    "    \n",
    "    # Create new headOrientation file\n",
    "    nameC = fileID + \"_headOrientation.csv\"\n",
    "    concatenated_headorientation.to_csv(os.path.join(compiled_folder, nameC), index=False)\n",
    "    \n",
    "    # Create a downsampled version of the headOrientation DataFrame (downsampled by 2)\n",
    "    downsampled_headorientation = concatenated_headorientation.iloc[::2].reset_index(drop=True)\n",
    "    nameD = fileID + \"_headOrientationDownsampled.csv\"\n",
    "    downsampled_headorientation.to_csv(os.path.join(compiled_folder, nameD), index=False)\n",
    "\n",
    "    update_concatenated_timeStamps(compiled_folder, nameA, fileID)\n",
    "    update_concatenated_timeStamps(compiled_folder, nameB, fileID)\n",
    "    update_concatenated_headorientation(compiled_folder, nameC, fileID)\n",
    "    update_concatenated_headorientation(compiled_folder, nameD, fileID)\n",
    "    \n",
    "\n",
    "# Process Imaging folders\n",
    "process_imaging_folders(parent_folders, output_folder)\n",
    "\n",
    "compiled_folder = os.path.join(output_folder, \"Imaging\")\n",
    "nameA = os.path.join(compiled_folder, fileID + \"_timeStamps.csv\")\n",
    "nameB = os.path.join(compiled_folder, fileID + \"_timeStampsDownsampled.csv\")\n",
    "# Move merged videos to shared folder for postion analysis (ie DeepLabCut)\n",
    "\n",
    "# Use the user-defined folder to create a downsampled folder\n",
    "downsampled_imaging_video_folder = imaging_video_folder + '_Downsampled'\n",
    "\n",
    "# Ensure the behavior_video_folder exists, or create it if it doesn't\n",
    "os.makedirs(imaging_video_folder, exist_ok=True)\n",
    "\n",
    "# Ensure the downsampled_behavior_video_folder exists, or create it if it doesn't\n",
    "os.makedirs(downsampled_imaging_video_folder, exist_ok=True)\n",
    "\n",
    "# Copy the concatenated video to the behavior_video_folder\n",
    "shutil.copy(nameA, imaging_video_folder)\n",
    "\n",
    "# Copy the concatenated video to the behavior_video_folder\n",
    "shutil.copy(nameB, downsampled_imaging_video_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6cfac3",
   "metadata": {},
   "source": [
    "# What next? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b17f43",
   "metadata": {},
   "source": [
    "1. Behavior --> position analysis (ie DeepLabCut) and pose annotation (manual or automated)\n",
    "2. Imaging --> calcium extraction (ie MinAn, CNMF-E etc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
